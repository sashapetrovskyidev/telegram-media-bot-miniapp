<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"/>
  <title>Music Visualizer</title>
  <script src="https://telegram.org/js/telegram-web-app.js"></script>
  <style>
    :root {
      --bg: #0a0e17;
      --accent: #a0a0ff;
      --glow: rgba(160,160,255,0.5);
    }
    body, html {
      margin: 0;
      padding: 0;
      height: 100%;
      overflow: hidden;
      background: var(--bg);
      font-family: system-ui, -apple-system, sans-serif;
      color: white;
    }
    #container {
      position: relative;
      width: 100%;
      height: 100%;
    }
    canvas {
      display: block;
    }
    #controls {
      position: absolute;
      bottom: 30px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 10;
      text-align: center;
      background: rgba(0,0,0,0.4);
      padding: 12px 24px;
      border-radius: 30px;
      backdrop-filter: blur(10px);
      border: 1px solid rgba(160,160,255,0.3);
    }
    button, label {
      padding: 10px 20px;
      margin: 6px;
      font-size: 1rem;
      background: rgba(160,160,255,0.15);
      border: 1px solid var(--accent);
      color: white;
      border-radius: 999px;
      cursor: pointer;
      transition: all 0.2s;
    }
    button:hover, label:hover {
      background: rgba(160,160,255,0.3);
      transform: translateY(-1px);
    }
    input[type="file"] {
      display: none;
    }
    #status {
      margin-top: 12px;
      font-size: 0.95rem;
      opacity: 0.85;
      max-width: 280px;
    }
  </style>
</head>
<body>
  <div id="container">
    <canvas id="canvas"></canvas>
  </div>

  <div id="controls">
    <label for="audioFile">Upload Song</label>
    <input type="file" id="audioFile" accept="audio/*" />
    <button id="micBtn">Live Mic</button>
    <button id="pauseBtn" disabled>Pause</button>
    <div id="status">Tap "Upload Song" or "Live Mic" to begin</div>
  </div>

  <script>
    const tg = window.Telegram.WebApp;
    tg.ready();
    tg.expand();

    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const status = document.getElementById('status');
    const pauseBtn = document.getElementById('pauseBtn');

    let audioCtx = null;
    let analyser = null;
    let source = null;
    let dataArray = null;
    let freqData = null;
    let particles = [];
    let audioElement = new Audio();
    let isPlaying = false;

    // Particle class
    class Particle {
      constructor() {
        this.reset();
      }
      reset() {
        this.x = canvas.width / 2 + (Math.random() - 0.5) * 200;
        this.y = canvas.height / 2 + (Math.random() - 0.5) * 200;
        this.size = Math.random() * 6 + 2;
        this.speedX = Math.random() * 8 - 4;
        this.speedY = Math.random() * 8 - 4;
        this.life = 1;
        this.hue = 190 + Math.random() * 80; // cyan-blue-purple
      }
      update(bass, mid, high) {
        this.x += this.speedX * (1 + bass / 60);
        this.y += this.speedY * (1 + mid / 90);
        this.life -= 0.012 + high / 4000;
        if (this.life <= 0) this.reset();
        this.hue = 180 + high * 1.2; // more cyan on highs
      }
      draw() {
        ctx.beginPath();
        ctx.arc(this.x, this.y, this.size * this.life * 1.8, 0, Math.PI * 2);
        ctx.fillStyle = `hsla(${this.hue}, 90%, 70%, ${this.life * 0.9})`;
        ctx.shadowBlur = 30;
        ctx.shadowColor = `hsla(${this.hue}, 90%, 70%, 0.8)`;
        ctx.fill();
      }
    }

    // Create particles
    for (let i = 0; i < 350; i++) particles.push(new Particle());

    // Resize canvas
    function resize() {
      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;
    }
    window.addEventListener('resize', resize);
    resize();

    // Draw loop
    function draw() {
      requestAnimationFrame(draw);

      // Gentle fade for trails
      ctx.fillStyle = 'rgba(10,14,23,0.10)';
      ctx.fillRect(0, 0, canvas.width, canvas.height);

      if (!analyser || !isPlaying) return;

      analyser.getByteTimeDomainData(dataArray);
      analyser.getByteFrequencyData(freqData);

      // Frequency groups
      const bass = freqData.slice(0, 30).reduce((a,b)=>a+b,0) / 30;
      const mid  = freqData.slice(30, 150).reduce((a,b)=>a+b,0) / 120;
      const high = freqData.slice(150).reduce((a,b)=>a+b,0) / (freqData.length - 150);

      // Strong beat → particle burst
      if (bass > 145) {
        for (let i = 0; i < 18; i++) {
          const p = particles[Math.floor(Math.random() * particles.length)];
          p.reset();
          p.speedX *= 2 + bass / 90;
          p.speedY *= 2 + bass / 90;
        }
      }

      // Central waveform
      ctx.beginPath();
      ctx.lineWidth = 6 + bass / 35;
      ctx.strokeStyle = `rgba(160,160,255,${0.65 + bass/280})`;
      const sliceWidth = canvas.width / dataArray.length;
      let x = 0;
      for (let i = 0; i < dataArray.length; i++) {
        const v = dataArray[i] / 128.0;
        const y = (v * canvas.height / 2) * (1 + mid / 140);
        if (i === 0) ctx.moveTo(x, y);
        else ctx.lineTo(x, y);
        x += sliceWidth;
      }
      ctx.lineTo(canvas.width, canvas.height / 2);
      ctx.stroke();

      // Particles
      particles.forEach(p => {
        p.update(bass, mid, high);
        p.draw();
      });

      // Pulsing central orb
      const vol = freqData.reduce((a,b)=>a+b,0) / freqData.length;
      ctx.beginPath();
      ctx.arc(canvas.width/2, canvas.height/2, 60 + vol * 0.45, 0, Math.PI*2);
      ctx.fillStyle = 'rgba(160,160,255,0.15)';
      ctx.shadowBlur = 100;
      ctx.shadowColor = 'rgba(160,160,255,0.9)';
      ctx.fill();
    }
    draw();

    // File upload
    document.getElementById('audioFile').onchange = e => {
      const file = e.target.files?.[0];
      if (!file) return;

      status.textContent = 'Loading track...';
      audioElement.src = URL.createObjectURL(file);
      audioElement.onloadedmetadata = () => {
        status.textContent = 'Starting visualization... tap if needed';
        startAudio();
        pauseBtn.disabled = false;
      };
      audioElement.onerror = () => {
        status.textContent = 'Cannot play this file — try MP3';
      };
    };

    // Mic input
    document.getElementById('micBtn').onclick = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioElement.srcObject = stream;
        audioElement.onloadedmetadata = () => {
          audioElement.play().catch(() => {
            status.textContent = 'Tap screen to start mic';
          });
          startAudio();
          status.textContent = 'Live mic active — make sound!';
          pauseBtn.disabled = false;
        };
      } catch (err) {
        status.textContent = 'Mic access denied — check Telegram settings';
        console.error(err);
      }
    };

    // Start / resume audio context
    async function startAudio() {
      if (!audioCtx) {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      }

      // Resume if suspended (very important in Mini Apps!)
      if (audioCtx.state === 'suspended') {
        await audioCtx.resume();
      }

      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048;
      dataArray = new Uint8Array(analyser.frequencyBinCount);
      freqData = new Uint8Array(analyser.frequencyBinCount);

      if (!source) {
        source = audioCtx.createMediaElementSource(audioElement);
        source.connect(analyser);
        analyser.connect(audioCtx.destination);
      }

      isPlaying = true;
      audioElement.play().catch(e => {
        console.log("Play blocked:", e);
        status.textContent = 'Tap anywhere on screen to start sound';
      });
    }

    // Pause / Resume
    pauseBtn.onclick = () => {
      if (isPlaying) {
        audioElement.pause();
        pauseBtn.textContent = 'Resume';
        status.textContent = 'Paused';
      } else {
        audioElement.play().catch(() => {});
        pauseBtn.textContent = 'Pause';
        status.textContent = 'Playing';
      }
      isPlaying = !isPlaying;
    };

    // Tap anywhere to resume audio context (fixes Mini App blocks)
    document.addEventListener('touchstart', async () => {
      if (audioCtx && audioCtx.state === 'suspended') {
        await audioCtx.resume();
        status.textContent = 'Audio context resumed — playing!';
      }
    }, { once: true });

    console.log('Music Visualizer loaded — tap Upload or Mic to begin');
  </script>
</body>
</html>